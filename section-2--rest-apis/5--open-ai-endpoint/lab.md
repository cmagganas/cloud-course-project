# Lab: Create AI-generated files using the OpenAI REST API

<figure align="center">
  <img src="../../assets/learning-aws-and-python.png" alt="Cute, generated image" width="350">
  <figcaption>You, completing this lab and generating content with OpenAI</figcaption>
</figure>

## Overview

This lab is self-directed and open-ended. 

The objective is to write one or more endpoints that save files to S3. The files should be generated by the OpenAI API.

## Resources

### OpenAI Demo [Notebook](https://mlops-club.github.io/openai-sdk.html)

- [`./notebooks/openai-sdk.ipynb`](https://mlops-club.github.io/openai-sdk.html) (source code [here](./notebooks/openai-sdk.ipynb)) shows you how to 
  1. Get an OpenAI API key
  1. use the OpenAI API with its SDK
  1. mock API calls performed by the SDK

  ![](../../assets/openai-sdk-demo-notebook.png)

### Reference implementation

For your own learning, I recommend you think about how to **design**, **implement**, and **test** endpoint(s) yourself.

However, if you get stuck, want to compare your solution, or simply want to skip through the lab, you can find a reference implementation in
[`./answer-key--reference-implementation`](./answer-key--reference-implementation).

There is a screenshot below of the design.

<details>

<summary>Click to reveal design in the reference implementation</summary>

<img src="../../assets/example-openai-endpoint.png" alt="OpenAI endpoint" width="700">
<p>After hitting this endpoint to generate a file, it can be viewed by hitting the <code>GET /files/{file_path}</code> endpoint.</p>

</details>

### Success criteria

- [ ] **Add at least one endpoint** that, when given a `prompt`, generates a files of type
  - [ ] image
  - [ ] audio
  - [ ] or text
  - [ ] And saves it to S3 with the proper mime type

- [ ] **Securely handle the OpenAI API secret key**, i.e. do not hard code it anywhere that could be committed

- [ ] Follow the principles outlined in the **API Design checklists** of the previous sections. 
  - [ ] Validate inputs
  - [ ] Handle edge/error cases
  - [ ] Generate the relevant metadata into the OpenAPI doc

- [ ] **Write tests for the endpoint(s)** you created
  - [ ] Test the happy path
  - [ ] Test edge/error cases
  - [ ] Consider mocking the OpenAI SDK for both testing and development to save money
  - [ ] Either
    - [ ] Run or tests in C.I. (including your mocking)
    - [ ] OR define a "pytest marker" to skip tests in C.I. that require hitting OpenAI's API.

